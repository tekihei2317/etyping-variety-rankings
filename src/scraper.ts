import puppeteer, { Browser, Page } from "puppeteer";
import { load } from "cheerio";
import { writeFileSync } from "fs";
import { RankingData, RankingEntry, VARIETY_CATEGORIES } from "./types.js";

/**
 * HTMLã‹ã‚‰ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’è§£æ
 */
function parseRankingHtml(categoryId: string, html: string): RankingData {
  const $ = load(html);
  const entries: RankingEntry[] = [];

  // ul.rankingå†…ã®liè¦ç´ ã‚’å‡¦ç†
  $("ul.ranking li").each((index, element) => {
    const $li = $(element);

    // ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
    if ($li.hasClass("head")) return;

    const rankText = $li.find(".rank").text().trim();
    const username = $li.find(".user").text().trim();
    const scoreText = $li.find(".score").text().trim();

    if (rankText && username && scoreText) {
      // ãƒ©ãƒ³ã‚¯ã‹ã‚‰æ•°å­—ã‚’æŠ½å‡ºï¼ˆ"1ä½" -> 1ï¼‰
      const rankNumber = parseInt(rankText.replace(/[^\d]/g, ""));
      // ã‚¹ã‚³ã‚¢ã‹ã‚‰æ•°å­—ã‚’æŠ½å‡º
      const score = parseInt(scoreText.replace(/[^\d]/g, ""));

      if (!isNaN(rankNumber) && !isNaN(score)) {
        entries.push({
          rank: rankNumber,
          username: username,
          score: score,
        });
      }
    }
  });

  console.log(`Parsed ${entries.length} ranking entries for ${categoryId}`);

  return {
    category: categoryId,
    entries: entries,
    fetchedAt: new Date(),
  };
}

/**
 * æŒ‡å®šãƒšãƒ¼ã‚¸ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
 */
async function scrapeSinglePage(
  page: Page,
  categoryId: string,
  pageNumber: number
): Promise<RankingEntry[]> {
  if (pageNumber > 1) {
    // 2ãƒšãƒ¼ã‚¸ç›®ä»¥é™ã®å ´åˆã€ps_page_move()ã‚’å®Ÿè¡Œ
    await page.evaluate((pageNum) => {
      (window as any).ps_page_move(pageNum);
    }, pageNumber);

    // ãƒšãƒ¼ã‚¸é·ç§»ã‚’å¾…ã¤
    await new Promise((resolve) => setTimeout(resolve, 2000));
  }

  const content = await page.content();
  const result = parseRankingHtml(categoryId, content);
  return result.entries;
}

/**
 * å…¨ãƒšãƒ¼ã‚¸ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
 */
async function scrapeAllPages(
  browser: Browser,
  categoryId: string,
  rankingUrl: string
): Promise<RankingData> {
  const startTime = Date.now();
  console.log(`Fetching all ranking data from: ${rankingUrl}`);

  const page = await browser.newPage();
  try {
    const gotoStartTime = Date.now();
    await page.goto(rankingUrl, { waitUntil: "domcontentloaded" });
    console.log(`Ranking page loaded in ${Date.now() - gotoStartTime}ms`);

    // JavaScriptãŒå®Ÿè¡Œã•ã‚Œã‚‹ã¾ã§å°‘ã—å¾…ã¤
    await new Promise((resolve) => setTimeout(resolve, 3000));

    // æœ€å¤§ãƒšãƒ¼ã‚¸æ•°ã‚’å–å¾—
    const maxPages = await page.evaluate(() => {
      return (window as any).ps_page_max || 1;
    });

    console.log(`Found ${maxPages} pages to scrape`);

    const allEntries: RankingEntry[] = [];

    // å„ãƒšãƒ¼ã‚¸ã‚’é †æ¬¡å–å¾—
    for (let pageNum = 1; pageNum <= maxPages; pageNum++) {
      console.log(`Scraping page ${pageNum}/${maxPages}...`);
      const pageStartTime = Date.now();

      const entries = await scrapeSinglePage(page, categoryId, pageNum);
      allEntries.push(...entries);

      console.log(
        `Page ${pageNum} completed in ${Date.now() - pageStartTime}ms (${
          entries.length
        } entries)`
      );
    }

    console.log(`Total entries collected: ${allEntries.length}`);

    return {
      category: categoryId,
      entries: allEntries,
      fetchedAt: new Date(),
      totalPages: maxPages,
    };
  } catch (error) {
    console.error(`Error scraping ranking for ${categoryId}:`, error);
    return {
      category: categoryId,
      entries: [],
      fetchedAt: new Date(),
    };
  } finally {
    await page.close();
    console.log(`scrapeAllPages completed in ${Date.now() - startTime}ms`);
  }
}

/**
 * æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°URLã‚’ç”Ÿæˆ
 */
function generateRankingUrl(categoryId: string): string {
  return `https://www.e-typing.ne.jp/ranking/index.asp?im=0&sc=variety&ct=${categoryId}`;
}

/**
 * æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—
 */
async function scrapeCategoryRanking(
  browser: Browser,
  categoryId: string
): Promise<RankingData> {
  const rankingUrl = generateRankingUrl(categoryId);
  return await scrapeAllPages(browser, categoryId, rankingUrl);
}

/**
 * å…¨ç¨®ç›®ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—
 */
async function scrapeAllCategories(browser: Browser): Promise<RankingData[]> {
  const allResults: RankingData[] = [];

  console.log(`Starting to scrape ${VARIETY_CATEGORIES.length} categories...`);

  for (const category of VARIETY_CATEGORIES) {
    console.log(`\n=== Scraping ${category.name} (${category.id}) ===`);
    const categoryStartTime = Date.now();

    try {
      const result = await scrapeCategoryRanking(browser, category.id);
      allResults.push(result);

      console.log(
        `âœ… ${category.name} completed in ${Date.now() - categoryStartTime}ms`
      );
      console.log(
        `   - ${result.entries.length} entries across ${
          result.totalPages || 1
        } pages`
      );

      // ã‚«ãƒ†ã‚´ãƒªé–“ã§å°‘ã—å¾…æ©Ÿï¼ˆe-typingã‚µãƒ¼ãƒãƒ¼ã«è² è·ã‚’ã‹ã‘ã™ããªã„ãŸã‚ï¼‰
      await new Promise((resolve) => setTimeout(resolve, 2000));
    } catch (error) {
      console.error(`âŒ Error scraping ${category.name}:`, error);
      // ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ä»–ã®ã‚«ãƒ†ã‚´ãƒªã®å‡¦ç†ã‚’ç¶šè¡Œ
      allResults.push({
        category: category.id,
        entries: [],
        fetchedAt: new Date(),
      });
    }
  }

  console.log(`\nğŸ‰ All categories completed!`);
  console.log(
    `Total entries collected: ${allResults.reduce(
      (sum, result) => sum + result.entries.length,
      0
    )}`
  );

  return allResults;
}

// ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†
async function main() {
  const totalStartTime = Date.now();
  console.log("Starting e-typing ranking scraper...");

  const browserStartTime = Date.now();
  const browser = await puppeteer.launch({
    headless: true,
    args: ["--no-sandbox", "--disable-setuid-sandbox"],
  });
  console.log(`Browser launched in ${Date.now() - browserStartTime}ms`);

  try {
    // å…¨ç¨®ç›®ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—
    const scrapeStartTime = Date.now();
    const allRankings = await scrapeAllCategories(browser);
    console.log(`All rankings scraped in ${Date.now() - scrapeStartTime}ms`);

    // å„ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    const today = new Date().toISOString().split("T")[0];
    allRankings.forEach((ranking) => {
      const filename = `data/${ranking.category}-ranking-${today}.json`;
      writeFileSync(filename, JSON.stringify(ranking, null, 2));
      console.log(
        `${ranking.category} data saved to: ${filename} (${ranking.entries.length} entries)`
      );
    });

    // çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    console.log("\nğŸ“Š Summary:");
    allRankings.forEach((ranking) => {
      const categoryInfo = VARIETY_CATEGORIES.find(
        (cat) => cat.id === ranking.category
      );
      const categoryName = categoryInfo?.name || ranking.category;
      console.log(`${categoryName}: ${ranking.entries.length} entries`);
    });
  } catch (error) {
    console.error("Error:", error);
  } finally {
    const closeStartTime = Date.now();
    await browser.close();
    console.log(`Browser closed in ${Date.now() - closeStartTime}ms`);
    console.log(`Total execution time: ${Date.now() - totalStartTime}ms`);
  }
}

// ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã®ã¿mainã‚’å®Ÿè¡Œ
if (import.meta.url === `file://${process.argv[1]}`) {
  main();
}
